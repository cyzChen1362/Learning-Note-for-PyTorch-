# ********************************************************************************
# é‡ç½®é—¨: Rt = Ïƒ(Xt Wxr + Htâˆ’1 Whr + br)
# æ›´æ–°é—¨: Zt = Ïƒ(Xt Wxz + Htâˆ’1 Whz + bz)
# å€™é€‰éšè—çŠ¶æ€: H~t = tanh(Xt Wxh + (Rt âŠ™ Htâˆ’1) Whh + bh)
# éšè—çŠ¶æ€: Ht = Zt âŠ™ Htâˆ’1 + (1 âˆ’ Zt) âŠ™ H~t
#
# å¾ˆæ˜¾ç„¶ï¼Œå¦‚æœå­¦ä¹ åˆ° Zt = 1ï¼Œåˆ™ç›¸å½“äºéšè—çŠ¶æ€ç›´æ¥ç»§æ‰¿ä¸Šä¸€æ—¶åˆ»çš„éšè—çŠ¶æ€ï¼Œå®Œå…¨ä¸è€ƒè™‘è¿™ä¸€æ—¶åˆ»çš„Xt
# å¦‚æœå­¦ä¹ åˆ° Zt = 0ï¼Œä»¥åŠ Rt = 1ï¼Œç›¸å½“äºå®Œå…¨ä¸è€ƒè™‘ä¸Šä¸€æ—¶åˆ»çš„éšè—çŠ¶æ€
# æ‰€ä»¥è¯´ï¼Œæ›´æ–°é—¨å¯ä»¥æ§åˆ¶é•¿æœŸè®°å¿†ï¼Œå†³å®šæ—§éšè—çŠ¶æ€â„ğ‘¡âˆ’1æœ‰å¤šå°‘ç›´æ¥â€œå¤åˆ¶â€åˆ°æ–°çŠ¶æ€ï¼Œé•¿æœŸä¾èµ–é å®ƒå®ç°
# é‡ç½®é—¨å¯ä»¥æ•æ‰çŸ­æœŸæ¨¡å¼ï¼Œå†³å®šè®¡ç®—å€™é€‰çŠ¶æ€â„~ğ‘¡æ—¶ï¼Œå‰ä¸€æ—¶åˆ»çš„éšè—çŠ¶æ€â„ğ‘¡âˆ’1å½±å“æœ‰å¤šå¤§ï¼ŒçŸ­æœŸä¾èµ–é å®ƒå®ç°
#
# æ›´æ–°é—¨æä¾›æ¥è¿‘æ’ç­‰æ˜ å°„ï¼šæ¢¯åº¦å¯ä»¥åœ¨æ—¶é—´æ–¹å‘æ— è¡°å‡åœ°æµåŠ¨
# é‡ç½®é—¨å…è®¸åœ¨éœ€è¦æ—¶â€œæ¸…ç©ºâ€è¿‡å»ï¼šé˜²æ­¢æ— å…³å†å²å™ªå£°ç§¯ç´¯ï¼Œå‡è½»æ¢¯åº¦çˆ†ç‚¸
# ********************************************************************************

"""
    é—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰
"""

# ========================
# è¯»å–æ•°æ®é›†
# ========================

import numpy as np
import torch
from torch import nn, optim
import torch.nn.functional as F

import sys
sys.path.append("..")
import d2lzh_pytorch as d2l
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()

# ========================
# åˆå§‹åŒ–æ¨¡å‹å‚æ•°
# ========================

num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size
print('will use', device)

def get_params():
    # å•ä¸€å‚æ•°çŸ©é˜µåˆå§‹åŒ–
    def _one(shape):
        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)
        return torch.nn.Parameter(ts, requires_grad=True)
    # ä¸¤ä¸ªå•ä¸€å‚æ•°çŸ©é˜µåˆå§‹åŒ– + 0åç½®åˆå§‹åŒ–åˆå¹¶
    def _three():
        return (_one((num_inputs, num_hiddens)),
                _one((num_hiddens, num_hiddens)),
                torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))

    W_xz, W_hz, b_z = _three()  # æ›´æ–°é—¨å‚æ•°
    W_xr, W_hr, b_r = _three()  # é‡ç½®é—¨å‚æ•°
    W_xh, W_hh, b_h = _three()  # å€™é€‰éšè—çŠ¶æ€å‚æ•°

    # è¾“å‡ºå±‚å‚æ•°
    W_hq = _one((num_hiddens, num_outputs))
    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True)
    return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])

# ========================
# å®šä¹‰æ¨¡å‹
# ========================

# éšè—çŠ¶æ€åˆå§‹åŒ–å‡½æ•°
def init_gru_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device=device), )

# æ ¹æ®é—¨æ§å¾ªç¯å•å…ƒçš„è®¡ç®—è¡¨è¾¾å¼å®šä¹‰æ¨¡å‹
def gru(inputs, state, params):
    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params
    H, = state
    outputs = []
    # è¿™é‡Œå’Œ Class4 ä¸€æ ·ï¼ŒX[t-1]æ˜¯ç¬¬t-1æ—¶é—´æ­¥çš„çŸ©é˜µï¼ŒX[t]æ˜¯ç¬¬tæ—¶é—´æ­¥çš„çŸ©é˜µ
    # X[t-1]é«˜ä¸ºbatch_sizeï¼Œå®½ä¸ºinput_num
    for X in inputs:
        # æ›´æ–°é—¨
        Z = torch.sigmoid(torch.matmul(X, W_xz) + torch.matmul(H, W_hz) + b_z)
        # é‡ç½®é—¨
        R = torch.sigmoid(torch.matmul(X, W_xr) + torch.matmul(H, W_hr) + b_r)
        # å€™é€‰éšè—çŠ¶æ€
        H_tilda = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(R * H, W_hh) + b_h)
        # éšè—çŠ¶æ€
        H = Z * H + (1 - Z) * H_tilda
        # è¾“å‡º
        Y = torch.matmul(H, W_hq) + b_q
        # åŒ Class4
        outputs.append(Y)
    return outputs, (H,)

# ========================
# è®­ç»ƒæ¨¡å‹å¹¶åˆ›ä½œæ­Œè¯
# ========================

num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2
pred_period, pred_len, prefixes = 40, 50, ['åˆ†å¼€', 'ä¸åˆ†å¼€']

# æ¯è¿‡40ä¸ªè¿­ä»£å‘¨æœŸä¾¿æ ¹æ®å½“å‰è®­ç»ƒçš„æ¨¡å‹åˆ›ä½œä¸€æ®µæ­Œè¯
d2l.train_and_predict_rnn(gru, get_params, init_gru_state, num_hiddens,
                          vocab_size, device, corpus_indices, idx_to_char,
                          char_to_idx, False, num_epochs, num_steps, lr,
                          clipping_theta, batch_size, pred_period, pred_len,
                          prefixes)

# ========================
# ç®€æ´å®ç°
# ========================

# ç›´æ¥è°ƒç”¨nnæ¨¡å—ä¸­çš„GRUç±»å³å¯
lr = 1e-2 # æ³¨æ„è°ƒæ•´å­¦ä¹ ç‡
gru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens)
model = d2l.RNNModel(gru_layer, vocab_size).to(device)
d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,
                                corpus_indices, idx_to_char, char_to_idx,
                                num_epochs, num_steps, lr, clipping_theta,
                                batch_size, pred_period, pred_len, prefixes)

