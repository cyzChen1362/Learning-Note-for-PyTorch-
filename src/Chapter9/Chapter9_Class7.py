r"""
å­¦ä¹ ç¬”è®°

åŸå§‹å·¥ç¨‹æ¥æºï¼š
    D2L (Dive into Deep Learning) ä¸­æ–‡ç‰ˆ
    ä»“åº“åœ°å€ï¼šhttps://github.com/d2l-ai/d2l-zh
    å®˜æ–¹ç½‘ç«™ï¼šhttps://zh.d2l.ai/

åŸå§‹æ–‡çŒ®å¼•ç”¨ï¼š
    @book{zhang2019dive,
        title={Dive into Deep Learning},
        author={Aston Zhang and Zachary C. Lipton and Mu Li and Alexander J. Smola},
        note={\url{https://zh.d2l.ai/}},
        year={2020}
    }

ç”¨é€”è¯´æ˜ï¼š
    æœ¬æ–‡ä»¶åŸºäºã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹ä¸­æ–‡ç‰ˆï¼ˆd2l-zhï¼‰åŠå…¶ä»£ç è¿›è¡Œå­¦ä¹ ä¸æ³¨é‡Šï¼Œ
    ä»…ä½œä¸ªäººå­¦ä¹ ç¬”è®°ä¸äº¤æµä¹‹ç”¨ï¼Œä¸ç”¨äºå•†ä¸šç”¨é€”ã€‚

è®¸å¯åè®®ï¼š
    åŸå·¥ç¨‹éµå¾ª Apache-2.0 è®¸å¯è¯ã€‚
"""


"""
    å•å‘å¤šæ¡†æ£€æµ‹ï¼ˆSSDï¼‰
"""

# ********************************************************************************
# åŸä¹¦ï¼šhttps://zh.d2l.ai/chapter_computer-vision/ssd.html
# ********************************************************************************

# ********************************************************************************
# ğŸ˜µè¿™ä¸ªç‰ˆæœ¬è®­ç»ƒä¸€è¶Ÿèµ·ç 10å°æ—¶ï¼Œåˆ«ç­‰äº†ï¼Œæˆ‘æœ‰Plusç‰ˆ
# ğŸ˜‰ç›´æ¥å¤§æ”¹ç‰¹æ”¹ï¼Œè¿ç»˜å›¾éƒ½æ”¹äº†ï¼Œè¦çœ‹ä¹Ÿåˆ«çœ‹è¿™ä¸ª
# ********************************************************************************

# ========================
# ç±»åˆ«é¢„æµ‹å±‚
# ========================

# ********************************************************************************
# å¤§æ¦‚æ„æ€å°±æ˜¯ï¼š
# ä¾‹å¦‚å¯¹æ¦‚ç‡é¢„æµ‹ï¼š
#
# 1.å·ç§¯è¾“å‡ºï¼š
# å°†ç‰¹å¾å›¾é€šè¿‡1*1æˆ–3*3å·ç§¯ï¼Œå¾—åˆ°ä¸€å¼  [a(q+1), h, w] çš„ç‰¹å¾å›¾ï¼›
# aï¼šæ¯ä¸ªåƒç´ ä½ç½®å¯¹åº”å¤šå°‘ä¸ªé”šæ¡†ï¼›q + 1ï¼šæ¯ä¸ªé”šæ¡†è¦é¢„æµ‹çš„ç±»åˆ«æ•°ï¼ˆå«èƒŒæ™¯ï¼‰
#
# 2. é€šé“åˆ†å—ï¼š
# æŠŠè¾“å‡ºé€šé“æŒ‰é”šæ¡†æ‹†åˆ†æˆ a ç»„ï¼Œæ¯ç»„æœ‰ (q+1) ä¸ªé€šé“ã€‚
# å¯¹äºç¬¬ k ä¸ªé”šæ¡†ï¼Œå–å‡ºç¬¬ k ç»„é€šé“ â‡’ å½¢çŠ¶æ˜¯ [q+1, h, w]
#
# 3.ç©ºé—´ä½ç½®å¯¹åº”ï¼š
# å¯¹äºè¾“å…¥ç‰¹å¾å›¾ä¸Šçš„æ¯ä¸ªä½ç½® (i, j)
# ç¬¬ k ç»„çš„ (i, j) å¤„æ˜¯ä¸€ç»„é•¿åº¦ q+1 çš„å‘é‡ã€‚
# è¿™ä¸ªå‘é‡å°±æ˜¯ â€œä»¥ (i, j) ä¸ºä¸­å¿ƒç”Ÿæˆçš„ç¬¬ k ä¸ªé”šæ¡†â€ å¯¹ q+1 ç±»åˆ« çš„é¢„æµ‹åˆ†æ•°
#
# 4.åç»­å¤„ç†ï¼š
# å¯¹è¿™ q+1 ä¸ªå€¼åš softmaxï¼ˆæˆ–sigmoidï¼Œçœ‹å…·ä½“å®ç°ï¼‰å¾—åˆ°æ¯ç±»çš„æ¦‚ç‡ã€‚
# å–æœ€å¤§æ¦‚ç‡çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç±»åˆ«ï¼Œä¹Ÿå¯ä»¥ç›´æ¥è¾“å‡ºæ•´ç»„æ¦‚ç‡ç”¨äºè®¡ç®—æŸå¤±ã€‚
# å›å½’åç§»é‡ï¼ˆbounding box regressionï¼‰ é€šå¸¸ç”±å¦ä¸€æ¡å·ç§¯å¤´è´Ÿè´£ï¼Œ
# å®ƒçš„è¾“å‡ºé€šé“æ•°æ˜¯ a Ã— 4ï¼ˆxã€yã€wã€h æˆ–å››ä¸ªåæ ‡ï¼‰ï¼Œç»“æ„å®Œå…¨ç±»ä¼¼ï¼Œåªæ˜¯é¢„æµ‹çš„æ˜¯ä½ç½®å‚æ•°ã€‚
# ********************************************************************************

# ********************************************************************************
# å…¨è¿æ¥å‚æ•°é‡ï¼š
# å…¨è¿æ¥è¾“å…¥ç»´åº¦ï¼šh Ã— w Ã— C
# å…¨è¿æ¥è¾“å‡ºå‚æ•°ï¼š(h Ã— w Ã— a Ã— (q + 1))
# æ€»å‚æ•°ï¼š(h Ã— w Ã— C) Ã— (h Ã— w Ã— a Ã— (q+1)) + h Ã— w Ã— a Ã— (q+1)
# å·ç§¯å‚æ•°é‡ï¼š
# è¾“å…¥é€šé“æ•°ï¼šC
# è¾“å‡ºé€šé“æ•°ï¼ša Ã— (q+1)
# æ€»å‚æ•°ï¼šk Ã— k Ã— C Ã— a Ã— (q+1) + a Ã— (q+1)
# å¯¹æ¯”ï¼š
# å‡è®¾k = 3ï¼ŒC = 256ï¼Œh = w = 38ï¼Œa = 3ï¼Œq = 20
# åˆ™å‚æ•°é‡åˆ†åˆ«æ˜¯3.37Ã—10Â¹â°å’Œ1.46Ã—10âµ
# ********************************************************************************

import torch
import torchvision
from torch import nn
from torch.nn import functional as F
import d2lzh_pytorch as d2l
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print("å½“å‰ device:", device)
print("CUDA å¯ç”¨:", torch.cuda.is_available())

print(torch.cuda.device_count())
for i in range(torch.cuda.device_count()):
    print(i, torch.cuda.get_device_name(i))

import time
from tqdm import tqdm   # è¿›åº¦æ¡åº“ï¼Œpip install tqdm

def cls_predictor(num_inputs, num_anchors, num_classes):
    return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1),
                     kernel_size=3, padding=1)

# ========================
# è¾¹ç•Œæ¡†é¢„æµ‹å±‚
# ========================

def bbox_predictor(num_inputs, num_anchors):
    return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1)

# ========================
# è¿ç»“å¤šå°ºåº¦çš„é¢„æµ‹
# ========================

def forward(x, block):
    return block(x)

Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))
Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))
print(Y1.shape)
print(Y2.shape)

def flatten_pred(pred):
    return torch.flatten(pred.permute(0, 2, 3, 1), start_dim=1)

def concat_preds(preds):
    return torch.cat([flatten_pred(p) for p in preds], dim=1)

print(concat_preds([Y1, Y2]).shape)

# ========================
# é«˜å’Œå®½å‡åŠå—
# ========================

def down_sample_blk(in_channels, out_channels):
    blk = []
    for _ in range(2):
        blk.append(nn.Conv2d(in_channels, out_channels,
                             kernel_size=3, padding=1))
        blk.append(nn.BatchNorm2d(out_channels))
        blk.append(nn.ReLU())
        in_channels = out_channels
    blk.append(nn.MaxPool2d(2))
    return nn.Sequential(*blk)

print(forward(torch.zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).shape)

# ========================
# åŸºæœ¬ç½‘ç»œå—
# ========================

def base_net():
    blk = []
    num_filters = [3, 16, 32, 64]
    for i in range(len(num_filters) - 1):
        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))
    return nn.Sequential(*blk)

print(forward(torch.zeros((2, 3, 256, 256)), base_net()).shape)

# ========================
# å®Œæ•´çš„æ¨¡å‹
# ========================

def get_blk(i):
    if i == 0:
        blk = base_net()
    elif i == 1:
        blk = down_sample_blk(64, 128)
    elif i == 4:
        blk = nn.AdaptiveMaxPool2d((1,1))
    else:
        blk = down_sample_blk(128, 128)
    return blk

def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):
    Y = blk(X)
    # è¿™é‡Œçš„æ—§ç‰ˆmultibox_prioræˆ‘æ¢æˆäº†æ–°ç‰ˆçš„MultiBoxPrior_torchï¼Œè¿™ä¿©è¾“å…¥è¾“å‡ºæ˜¯å®Œå…¨ä¸€è‡´çš„
    anchors = d2l.MultiBoxPrior_torch(Y, sizes=size, ratios=ratio)
    cls_preds = cls_predictor(Y)
    bbox_preds = bbox_predictor(Y)
    return (Y, anchors, cls_preds, bbox_preds)

sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],
         [0.88, 0.961]]
ratios = [[1, 2, 0.5]] * 5
num_anchors = len(sizes[0]) + len(ratios[0]) - 1

class TinySSD(nn.Module):
    def __init__(self, num_classes, **kwargs):
        super(TinySSD, self).__init__(**kwargs)
        self.num_classes = num_classes
        idx_to_in_channels = [64, 128, 128, 128, 128]
        for i in range(5):
            # å³èµ‹å€¼è¯­å¥self.blk_i=get_blk(i)
            setattr(self, f'blk_{i}', get_blk(i))
            setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i],
                                                    num_anchors, num_classes))
            setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i],
                                                      num_anchors))

    def forward(self, X):
        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5
        for i in range(5):
            # getattr(self,'blk_%d'%i)å³è®¿é—®self.blk_i
            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(
                X, getattr(self, f'blk_{i}'), sizes[i], ratios[i],
                getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}'))
        anchors = torch.cat(anchors, dim=1)
        cls_preds = concat_preds(cls_preds)
        cls_preds = cls_preds.reshape(
            cls_preds.shape[0], -1, self.num_classes + 1)
        bbox_preds = concat_preds(bbox_preds)
        return anchors, cls_preds, bbox_preds

net = TinySSD(num_classes=1)
X = torch.zeros((32, 3, 256, 256))
anchors, cls_preds, bbox_preds = net(X)

print('output anchors:', anchors.shape)
print('output class preds:', cls_preds.shape)
print('output bbox preds:', bbox_preds.shape)

# ========================
# è¯»å–æ•°æ®é›†å’Œåˆå§‹åŒ–
# ========================

batch_size = 256
train_iter, _ = d2l.load_data_bananas(batch_size)

net = TinySSD(num_classes=1)
trainer = torch.optim.SGD(net.parameters(), lr=0.2, weight_decay=5e-4)

# ========================
# å®šä¹‰æŸå¤±å‡½æ•°å’Œè¯„ä»·å‡½æ•°
# ========================

cls_loss = nn.CrossEntropyLoss(reduction='none')
bbox_loss = nn.L1Loss(reduction='none')

def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks):
    batch_size, num_classes = cls_preds.shape[0], cls_preds.shape[2]
    cls = cls_loss(cls_preds.reshape(-1, num_classes),
                   cls_labels.reshape(-1)).reshape(batch_size, -1).mean(dim=1)
    bbox = bbox_loss(bbox_preds * bbox_masks,
                     bbox_labels * bbox_masks).mean(dim=1)
    return cls + bbox

def cls_eval(cls_preds, cls_labels):
    # ç”±äºç±»åˆ«é¢„æµ‹ç»“æœæ”¾åœ¨æœ€åä¸€ç»´ï¼Œargmaxéœ€è¦æŒ‡å®šæœ€åä¸€ç»´ã€‚
    return float((cls_preds.argmax(dim=-1).type(
        cls_labels.dtype) == cls_labels).sum())

def bbox_eval(bbox_preds, bbox_labels, bbox_masks):
    return float((torch.abs((bbox_labels - bbox_preds) * bbox_masks)).sum())

# ========================
# è®­ç»ƒæ¨¡å‹
# ========================

num_epochs= 20
animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                        legend=['class error', 'bbox mae'])
net = net.to(device)
global_start = time.time()

for epoch in range(num_epochs):
    epoch_start = time.time()
    metric = d2l.Accumulator(4)
    net.train()

    # è®°å½•ä¸Šä¸€ä¸ª batch ç»“æŸæ—¶é—´ï¼Œç”¨äºè®¡ç®—æ•°æ®åŠ è½½è€—æ—¶
    last_end = epoch_start

    for features, target in tqdm(train_iter,
                                 desc=f"Epoch {epoch + 1}/{num_epochs}",
                                 leave=False):
        t0 = time.time()
        data_load_time = t0 - last_end           # ä»…æ•°æ®åŠ è½½æ—¶é—´

        # --- æ•°æ®æ¬è¿åˆ° GPU ---
        t1 = time.time()
        X = features.to(device, non_blocking=True)
        Y = target.to(device, non_blocking=True)
        to_gpu_time = time.time() - t1

        # --- å‰å‘ã€åå‘ã€æ›´æ–° ---
        t2 = time.time()
        trainer.zero_grad()
        anchors, cls_preds, bbox_preds = net(X)
        bbox_labels, bbox_masks, cls_labels = d2l.MultiBoxTarget(
            anchors.to(device), Y.to(device))
        l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks)
        l.mean().backward()
        trainer.step()
        train_time = time.time() - t2

        # ç´¯åŠ æŒ‡æ ‡
        metric.add(cls_eval(cls_preds, cls_labels), cls_labels.numel(),
                   bbox_eval(bbox_preds, bbox_labels, bbox_masks),
                   bbox_labels.numel())

        # æ‰“å°å„é˜¶æ®µè€—æ—¶
        print(f"  load:{data_load_time:.3f}s | toGPU:{to_gpu_time:.3f}s | "
              f"train:{train_time:.3f}s | total:{time.time()-t0:.3f}s")

        last_end = time.time()   # ä¸‹ä¸ª batch è®¡ç®—æ•°æ®åŠ è½½æ—¶é—´çš„åŸºå‡†

    cls_err, bbox_mae = 1 - metric[0] / metric[1], metric[2] / metric[3]
    animator.add(epoch + 1, (cls_err, bbox_mae))
    print(f"Epoch {epoch + 1} å®Œæˆ, ç”¨æ—¶ {time.time() - epoch_start:.2f} ç§’ "
          f"(cls_err {cls_err:.3f}, bbox_mae {bbox_mae:.3f})")

total_time = time.time() - global_start
print(f"\nè®­ç»ƒæ€»è€—æ—¶: {total_time:.2f} ç§’, å¹³å‡ {total_time / num_epochs:.2f} ç§’/epoch")
